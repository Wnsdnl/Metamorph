from fastapi import FastAPI, Request
from pydantic import BaseModel
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import os

# í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ì§ì ‘ ì…ë ¥
os.environ["OPENAI_API_KEY"] = "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"

# FastAPI ì•± ìƒì„±
app = FastAPI()

# ë°ì´í„° í´ë˜ìŠ¤: ì§ˆë¬¸ ë°›ê¸°ìš©
class QueryRequest(BaseModel):
    query: str

# 1. ì„ë² ë”© ë° ë²¡í„°DB ë¡œë”©
print("FAISS ì¸ë±ìŠ¤ ë¡œë”© ì¤‘...")
embedding_model = OpenAIEmbeddings(
    model="text-embedding-3-small"
)

db = FAISS.load_local("embeddings/vehicle_manual_index", embedding_model, allow_dangerous_deserialization=True)

# 2. LLM (OpenAI GPT-4o)
print("OpenAI LLM ì„¤ì • ì¤‘...")
llm = ChatOpenAI(model="gpt-4o", temperature=0.3)

# 3. LangChain Retrieval QA ì²´ì¸
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever = db.as_retriever(search_kwargs={"k": 10}),
    chain_type_kwargs={
        "prompt": PromptTemplate(
            input_variables=["context", "question"],
            template="""
                    ë‹¹ì‹ ì€ ì°¨ëŸ‰ ë§¤ë‰´ì–¼ ì•ˆë‚´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                    
                    ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì´ ë¹„ê³µì‹ì ì´ê³  ëª¨í˜¸í•˜ê³ , ê³µì‹ ì°¨ëŸ‰ ë©”ë‰´ì–¼ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ì„ ê±° ê°™ì€ ë‹¨ì–´ì—¬ë„, ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ìœ ì¶”í•´ì„œ
                    ê³µì‹ ì°¨ëŸ‰ ë§¤ë‰´ì–¼ì—ì„œ ê²€ìƒ‰í•˜ê¸° ì¢‹ì€ í˜•íƒœì˜ ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.
                    ì˜ˆ:
                    ì—‰ëœ¨ -> ì¢Œì„ íˆí„°

                    ê·¸ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ì¤€ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
                    ë‹µë³€ì€ ìµœëŒ€ 3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê³  í•µì‹¬ë§Œ ë‹´ì•„ ìš´ì „ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. (ë‹µë³€ì„ ì œê³µí•  ë• ì˜¤ë¡œì§€ ë‹µë³€ë§Œ í•´ì£¼ì„¸ìš”.)
                    ì •ë³´ê°€ 'ì „í˜€' ì—†ì„ ê²½ìš°ì—ë§Œ ë‹¹ì‹ ì´ ì•Œê³  ìˆëŠ” ì„ ì—ì„œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

                    ë¬¸ì„œ:
                    {context}

                    ì§ˆë¬¸:
                    {question}

                    ë‹µë³€:"""
                            )
                        }
                    )

@app.post("/ask")
async def ask_question(request: QueryRequest):
    query = request.query
    relevant_docs = db.as_retriever(search_kwargs={"k": 10}).get_relevant_documents(query)
    print(f"ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(relevant_docs)}")
    
    for i, doc in enumerate(relevant_docs):
        print(f"\nğŸ“„ ë¬¸ì„œ {i+1} ë‚´ìš©:\n{doc.page_content[:500]}")
        
    print(f"ì§ˆë¬¸ ìˆ˜ì‹ : {query}")

    try:
        answer_dict = qa_chain.invoke(query)
        answer = answer_dict["result"]
        answer = answer.replace("**", "").replace("\n", " ").strip()
        print(f"ì‘ë‹µ ìƒì„± ì™„ë£Œ: {answer}")
        return {"answer": answer}
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"error": str(e)}